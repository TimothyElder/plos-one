<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">PLoS ONE</journal-id>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="pmc">plosone</journal-id>
      <journal-title-group>
        <journal-title>PLoS ONE</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1932-6203</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PONE-D-12-16275</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pone.0050280</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Sensory systems</subject>
              <subj-group>
                <subject>Visual system</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory perception</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Medicine</subject>
          <subj-group>
            <subject>Mental health</subject>
            <subj-group>
              <subject>Psychology</subject>
              <subj-group>
                <subject>Behavior</subject>
                <subj-group>
                  <subject>Emotions</subject>
                </subj-group>
              </subj-group>
              <subj-group>
                <subject>Cognitive psychology</subject>
                <subject>Experimental psychology</subject>
                <subject>Human relations</subject>
                <subject>Sensory perception</subject>
                <subject>Social psychology</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Anthropology</subject>
            <subj-group>
              <subject>Cultural anthropology</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Behavior</subject>
              <subj-group>
                <subject>Emotions</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Cognitive psychology</subject>
              <subject>Experimental psychology</subject>
              <subject>Human relations</subject>
              <subject>Sensory perception</subject>
              <subject>Social psychology</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Sociology</subject>
            <subj-group>
              <subject>Culture</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Mental Health</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>The Mysterious Noh Mask: Contribution of Multiple Facial Parts to the Recognition of Emotional Expressions</article-title>
        <alt-title alt-title-type="running-head">The Mysterious Noh Mask</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Miyata</surname>
            <given-names>Hiromitsu</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Nishimura</surname>
            <given-names>Ritsuko</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Okanoya</surname>
            <given-names>Kazuo</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kawai</surname>
            <given-names>Nobuyuki</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Okanoya Emotional Information Project (OEIP), Exploratory Research for Advanced Technology (ERATO), Japan Science and Technology Agency (JST), Nagoya, Japan</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Okanoya Emotional Information Project (OEIP), Exploratory Research for Advanced Technology (ERATO), Japan Science and Technology Agency (JST), Wako, Japan</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Graduate School of Arts and Sciences, The University of Tokyo, Tokyo, Japan</addr-line>
      </aff>
      <aff id="aff4">
        <label>4</label>
        <addr-line>Brain Science Institute (BSI), RIKEN, Wako, Japan</addr-line>
      </aff>
      <aff id="aff5">
        <label>5</label>
        <addr-line>Graduate School of Information Science, Nagoya University, Nagoya, Japan</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Kemp</surname>
            <given-names>Andrew H.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>University of Sydney, Australia</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">kawai@is.nagoya-u.ac.jp</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: RN KO. Performed the experiments: RN. Analyzed the data: RN HM. Wrote the paper: HM. Arrangement of the study: NK.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <year>2012</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>21</day>
        <month>11</month>
        <year>2012</year>
      </pub-date>
      <volume>7</volume>
      <issue>11</issue>
      <elocation-id>e50280</elocation-id>
      <history>
        <date date-type="received">
          <day>28</day>
          <month>5</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>23</day>
          <month>10</month>
          <year>2012</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2012</copyright-year>
        <copyright-holder>Miyata et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <sec>
          <title>Background</title>
          <p>A Noh mask worn by expert actors when performing on a Japanese traditional Noh drama is suggested to convey countless different facial expressions according to different angles of head/body orientation. The present study addressed the question of how different facial parts of a Noh mask, including the eyebrows, the eyes, and the mouth, may contribute to different emotional expressions. Both experimental situations of active creation and passive recognition of emotional facial expressions were introduced.</p>
        </sec>
        <sec>
          <title>Methodology/Principal Findings</title>
          <p>In Experiment 1, participants either created happy or sad facial expressions, or imitated a face that looked up or down, by actively changing each facial part of a Noh mask image presented on a computer screen. For an upward tilted mask, the eyebrows and the mouth shared common features with sad expressions, whereas the eyes with happy expressions. This contingency tended to be reversed for a downward tilted mask. Experiment 2 further examined which facial parts of a Noh mask are crucial in determining emotional expressions. Participants were exposed to the synthesized Noh mask images with different facial parts expressing different emotions. Results clearly revealed that participants primarily used the shape of the mouth in judging emotions. The facial images having the mouth of an upward/downward tilted Noh mask strongly tended to be evaluated as sad/happy, respectively.</p>
        </sec>
        <sec>
          <title>Conclusions/Significance</title>
          <p>The results suggest that Noh masks express chimeric emotional patterns, with different facial parts conveying different emotions This appears consistent with the principles of Noh which highly appreciate subtle and composite emotional expressions, as well as with the mysterious facial expressions observed in Western art. It was further demonstrated that the mouth serves as a diagnostic feature in characterizing the emotional expressions. This indicates the superiority of biologically-driven factors over the traditionally formulated performing styles when evaluating the emotions of the Noh masks.</p>
        </sec>
      </abstract>
      <funding-group>
        <funding-statement>This study was supported by the funding from the Japan Science and Technology Agency, Exploratory Research for Advanced Technology, Okanoya Emotional Information Project. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="9"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Noh refers to a major form of Japanese traditional musical drama performed since the 14th century, i.e., the latter half of the Kamakura period in Japan’s history (for an overview, see <xref ref-type="bibr" rid="pone.0050280-Komparu1">[1]</xref>–<xref ref-type="bibr" rid="pone.0050280-Waley1">[2]</xref>). It is characterized by extremely symbolized conventional performing styles. A Noh mask worn by skilled actors during performance is a hard wooden mask having fixed properties of facial components. At first glance, it often appears expressionless or mysterious, with specific emotions difficult to be attributed. However, the Noh dramas nevertheless involve multiple scenes in which various emotions of the characters are expressed. Instead of bearing no expressions, the Noh mask can be regarded to potentially convey all kinds of different emotions, i.e., “<italic>mugen hyojo</italic> (infinite facial expressions)”, according to different orientations of the head as well as the body <xref ref-type="bibr" rid="pone.0050280-Inoue1">[3]</xref>–<xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref>. Specifically, in the convention of the Noh drama, the mask is turned upwards when signifying a happy state, a gesture known as <italic>terasu</italic> (shining). By contrast, the mask is turned downwards when signifying a sad state, known as <italic>kumorasu</italic> (clouding) <xref ref-type="bibr" rid="pone.0050280-Inoue1">[3]</xref>.</p>
      <p>The question posited here is whether observers recognize emotional expressions in a Noh mask in the same ways as the rules of the drama intend to convey. Lyons et al. <xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref> examined how British and Japanese participants perceive facial expressions in a Noh mask shown at systematically different angles of inclination. Participants from both cultural groups tended to attribute happiness to a downward tilted mask, and sadness to a upward tilted mask. This trend remained consistent both when the facial image of chin and upper head contour was cropped, and when human face images were used instead of Noh mask images. These data were opposite to the conventional styles of the Noh drama. The facial action coding system (FACS), developed by Ekman and Friesen <xref ref-type="bibr" rid="pone.0050280-Ekman1">[6]</xref>, was applied to interpret these results. Specifically, the downward tilted mask suggested raised cheek and pulled lip corner, which are elements of a happy expression. By contrast, the sad expression of the upward tilted mask was suggested to be mainly conveyed by raised inner brow and depressed lip corner. These interpretations were also in agreement with Kappas et al. <xref ref-type="bibr" rid="pone.0050280-Kappas1">[7]</xref>, suggesting that vertical viewing angles alter the appearance of facial parts. For example, lip corners seen from above and below appear to be drawn upwards (as if being happy) and downwards (as if being sad), respectively. Minoshita et al. <xref ref-type="bibr" rid="pone.0050280-Minoshita1">[8]</xref> also confirmed these findings by analyzing larger numbers of emotional categories. For example, downward tilted masks were recognized as happier, more composed, and less surprised, compared with upward tilted masks (see also <xref ref-type="bibr" rid="pone.0050280-Minoshita2">[9]</xref>–<xref ref-type="bibr" rid="pone.0050280-Minoshita3">[10]</xref>).</p>
      <p>Nishimura et al. <xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref> further examined whether not only head inclination but also body postures of the <italic>shite</italic> (the main actor) may contribute to the viewers’ recognition of the emotional expressions. They used a downloaded succession of pictures that included either the face alone, or the body together with the face, while the actor was looking down to play a stylized sad act of a Noh drama. In both conditions, pictures with small downward inclinations tended to be recognized as relatively sadder, while those with larger inclinations as relatively happier. These trends were stronger for the pictures that included the whole body posture. Hiding the hand from the picture of the body failed to significantly alter these trends. Nishimura et al. <xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref> argued that emotions expressed by the whole body postures had stronger effects than those by a Noh mask alone, and that the actor’s initial movements may have determined the labels of emotions in both these conditions.</p>
      <p>These preceding studies conducted so far are in agreement that inclination of the head as well as the body in the course of successive actions plays a significant role in the recognition of emotional expressions during Noh performance. The results, however, show trends opposite to the traditional rules of Noh <xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref>–<xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref>. To resolve these apparent contradictions, it should be beneficial to systematically examine how different facial parts contribute to the recognition of the emotional expressions, in either frontal or tilted pictures of Noh masks. For example, if certain part of a face consistently plays a primary role in the judgment of the emotional expressions, that facial part would turn out to be a biologically dominant factor in emotion recognition. As Ekman and Friesen <xref ref-type="bibr" rid="pone.0050280-Ekman2">[11]</xref> indicated, there could be emotional facial expressions that are biologically-based and are consistent across people from different cultures (see also <xref ref-type="bibr" rid="pone.0050280-Ekman3">[12]</xref>–<xref ref-type="bibr" rid="pone.0050280-Elfenbein2">[15]</xref>). By contrast, if the recognition of emotions consistently corresponds to the conventional rules of Noh, that would indicate the strong influence of historically formulated styles of the Noh drama on the recognition of emotion. In other words, detailed analyses of the viewers’ recognition of facial expressions and comparing them with the rules of Noh should help to elucidate the potential interactions between biologically-driven factors and culturally accumulated conventions in Japanese traditional art.</p>
      <p>The purpose of the present research was to systematically examine how, and in what weight, different facial parts of a frontal or tilted Noh mask contribute to the recognition of different emotional expressions. Japanese participants were tested in both contexts of active creation (Experiment 1) and passive recognition (Experiment 2) of emotional facial expressions, using pictures of Noh masks presented on a computer display. Both experiments aimed to elucidate how facial components, including the eyebrows, the eyes and the mouth, may play significant roles in forming the happy or sad impressions of the mask as a whole.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Experiment 1</title>
        <p>For each of the four conditions, i.e., happy, sad, upward tilted, and downward tilted (<xref ref-type="fig" rid="pone-0050280-g001"><bold>Figure 1</bold></xref>), <xref ref-type="table" rid="pone-0050280-t001"><bold>Table 1</bold></xref> summarizes rating values at each of the controllers averaged across participants. For each condition and facial action, one-sample <italic>t</italic>-tests with Bonferroni correction made comparisons with zero, to reveal the significantly manipulated controllers. Data for these conditions were then compared with each other, to examine which facial parts may share comparable changing patterns between happy/sad expressions and upward/downward tilted expressions. To describe these results, for the upward tilted condition, statistically significant components of facial actions such as raising the inner eyebrow (AU 1), depressing the lip corner (AU 15), and raising the chin (AU 17) corresponded to those observed for the sad condition. By contrast, raising the upper lid to wide open the eyes (AU5) for the upward tilted condition corresponded to that found for the happy condition. Data for the downward tilted condition overall showed trends opposite to those for the upward tilted condition, even though statistical support for this condition was relatively weak. Specifically, lack of lowering the outer brow (AUs 1 and 4), the trend to pull up the lip corner (AU 13), and lack of raising the chin (AU17) observed for the downward tilted condition corresponded to those for the happy condition. By contrast, the trend to make the eyes less open (AU 7) found for the downward tilted condition was parallel to that for the sad condition.</p>
        <fig id="pone-0050280-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Examples of the Noh mask images in Experiment 1.</title>
            <p>(<bold>A</bold>) shows the frontal image of the Koomote mask presented at the beginning phase for all the four conditions. Participants changed facial parts of this image to create expressions according to the instructions given in each condition. (<bold>B</bold>) and (<bold>C</bold>) show the examples of faces that participants created in the happy and sad conditions, respectively. (<bold>D</bold>) and (<bold>E</bold>) show the upward tilted and downward tilted Koomote masks presented simultaneously with the frontal image in these conditions. (<bold>F</bold>) and (<bold>G</bold>) show the examples of faces that participants created by imitating (<bold>D</bold>) and (<bold>E</bold>), respectively.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.g001" position="float" xlink:type="simple"/>
        </fig>
        <table-wrap id="pone-0050280-t001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>Results of Experiment 1.</title>
          </caption>
          <alternatives>
            <graphic id="pone-0050280-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.t001" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" rowspan="1" colspan="1">FACS name</td>
                  <td align="left" rowspan="1" colspan="1">AU</td>
                  <td colspan="4" align="left" rowspan="1">condition</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">upward tilted</td>
                  <td align="left" rowspan="1" colspan="1">downward tilted</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Inner Brow Raiser</td>
                  <td align="left" rowspan="1" colspan="1">AU1</td>
                  <td align="left" rowspan="1" colspan="1">26.6 (7.7)</td>
                  <td align="left" rowspan="1" colspan="1">68.4*** (9.6)</td>
                  <td align="left" rowspan="1" colspan="1">30.3*** (3.9)</td>
                  <td align="left" rowspan="1" colspan="1">7.0 (4.1)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Outer Brow Raiser</td>
                  <td align="left" rowspan="1" colspan="1">AU2</td>
                  <td align="left" rowspan="1" colspan="1">14.7 (7.2)</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                  <td align="left" rowspan="1" colspan="1">0.1 (0.1)</td>
                  <td align="left" rowspan="1" colspan="1">9.0 (3.6)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Brow Lowerer</td>
                  <td align="left" rowspan="1" colspan="1">AU4</td>
                  <td align="left" rowspan="1" colspan="1">3.7 (2.0)</td>
                  <td align="left" rowspan="1" colspan="1">59.9** (10.5)</td>
                  <td align="left" rowspan="1" colspan="1">3.8 (2.2)</td>
                  <td align="left" rowspan="1" colspan="1">25.1 (8.9)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Upper Lid Raiser</td>
                  <td align="left" rowspan="1" colspan="1">AU5</td>
                  <td align="left" rowspan="1" colspan="1">45.6** (8.3)</td>
                  <td align="left" rowspan="1" colspan="1">22.4 (8.2)</td>
                  <td align="left" rowspan="1" colspan="1">24.6* (5.9)</td>
                  <td align="left" rowspan="1" colspan="1">13.5 (4.8)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lid Tightener</td>
                  <td align="left" rowspan="1" colspan="1">AU7</td>
                  <td align="left" rowspan="1" colspan="1">4.9 (2.9)</td>
                  <td align="left" rowspan="1" colspan="1">17.2 (6.3)</td>
                  <td align="left" rowspan="1" colspan="1">1.2 (1.2)</td>
                  <td align="left" rowspan="1" colspan="1">13.1<sup>+</sup> (3.7)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Eyes Closed</td>
                  <td align="left" rowspan="1" colspan="1">AU43</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                  <td align="left" rowspan="1" colspan="1">9.6 (3.3)</td>
                  <td align="left" rowspan="1" colspan="1">0.1 (0.1)</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Cheek Raiser</td>
                  <td align="left" rowspan="1" colspan="1">AU6</td>
                  <td align="left" rowspan="1" colspan="1">60.8*** (8.2)</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                  <td align="left" rowspan="1" colspan="1">2.9 (1.4)</td>
                  <td align="left" rowspan="1" colspan="1">21.1<sup>+</sup> (6.1)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Nose Wrinkler</td>
                  <td align="left" rowspan="1" colspan="1">AU9</td>
                  <td align="left" rowspan="1" colspan="1">0.6 (0.6)</td>
                  <td align="left" rowspan="1" colspan="1">18.5 (6.0)</td>
                  <td align="left" rowspan="1" colspan="1">4.3 (2.3)</td>
                  <td align="left" rowspan="1" colspan="1">1.2 (0.8)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lip Corner Puller</td>
                  <td align="left" rowspan="1" colspan="1">AU12</td>
                  <td align="left" rowspan="1" colspan="1">72.3*** (8.2)</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                  <td align="left" rowspan="1" colspan="1">7.6 (6.9)</td>
                  <td align="left" rowspan="1" colspan="1">8.9 (3.9)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Sharp Lip Puller</td>
                  <td align="left" rowspan="1" colspan="1">AU13</td>
                  <td align="left" rowspan="1" colspan="1">45.4** (8.7)</td>
                  <td align="left" rowspan="1" colspan="1">1.6 (1.4)</td>
                  <td align="left" rowspan="1" colspan="1">6.0 (2.7)</td>
                  <td align="left" rowspan="1" colspan="1">17.5<sup>+</sup> (4.6)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lip Corner Depressor</td>
                  <td align="left" rowspan="1" colspan="1">AU15</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                  <td align="left" rowspan="1" colspan="1">100.0 (0.0)</td>
                  <td align="left" rowspan="1" colspan="1">31.4** (6.3)</td>
                  <td align="left" rowspan="1" colspan="1">9.8 (4.3)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lip Stretcher</td>
                  <td align="left" rowspan="1" colspan="1">AU20</td>
                  <td align="left" rowspan="1" colspan="1">39.2** (7.7)</td>
                  <td align="left" rowspan="1" colspan="1">68.8*** (8.7)</td>
                  <td align="left" rowspan="1" colspan="1">5.0 (2.5)</td>
                  <td align="left" rowspan="1" colspan="1">6.2 (3.3)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Upper Lip Raiser</td>
                  <td align="left" rowspan="1" colspan="1">AU10</td>
                  <td align="left" rowspan="1" colspan="1">13.1 (7.2)</td>
                  <td align="left" rowspan="1" colspan="1">13.2 (5.0)</td>
                  <td align="left" rowspan="1" colspan="1">13.4 (4.7)</td>
                  <td align="left" rowspan="1" colspan="1">2.4 (1.8)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lower Lip Depressor</td>
                  <td align="left" rowspan="1" colspan="1">AU16</td>
                  <td align="left" rowspan="1" colspan="1">36.1<sup>+</sup> (10.0)</td>
                  <td align="left" rowspan="1" colspan="1">0.1 (0.1)</td>
                  <td align="left" rowspan="1" colspan="1">7.1 (3.8)</td>
                  <td align="left" rowspan="1" colspan="1">6.8 (2.5)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lip Pucker</td>
                  <td align="left" rowspan="1" colspan="1">AU18</td>
                  <td align="left" rowspan="1" colspan="1">3.9 (3.7)</td>
                  <td align="left" rowspan="1" colspan="1">0.4 (0.4)</td>
                  <td align="left" rowspan="1" colspan="1">19.1* (4.9)</td>
                  <td align="left" rowspan="1" colspan="1">15.0 (5.3)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lip Tightener</td>
                  <td align="left" rowspan="1" colspan="1">AU23</td>
                  <td align="left" rowspan="1" colspan="1">4.1 (3.0)</td>
                  <td align="left" rowspan="1" colspan="1">47.4* (10.3)</td>
                  <td align="left" rowspan="1" colspan="1">7.1 (4.0)</td>
                  <td align="left" rowspan="1" colspan="1">25.1** (4.8)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lip Pressor</td>
                  <td align="left" rowspan="1" colspan="1">AU24</td>
                  <td align="left" rowspan="1" colspan="1">5.4 (5.2)</td>
                  <td align="left" rowspan="1" colspan="1">20.1<sup>+</sup> (5.6)</td>
                  <td align="left" rowspan="1" colspan="1">5.6 (2.8)</td>
                  <td align="left" rowspan="1" colspan="1">7.4 (3.7)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Mouth Stretch</td>
                  <td align="left" rowspan="1" colspan="1">AU27</td>
                  <td align="left" rowspan="1" colspan="1">18.9 (6.9)</td>
                  <td align="left" rowspan="1" colspan="1">5.6 (4.0)</td>
                  <td align="left" rowspan="1" colspan="1">4.6 (2.2)</td>
                  <td align="left" rowspan="1" colspan="1">0.0 (0.0)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Lips Part</td>
                  <td align="left" rowspan="1" colspan="1">AU25</td>
                  <td align="left" rowspan="1" colspan="1">10.8 (4.2)</td>
                  <td align="left" rowspan="1" colspan="1">2.3 (1.7)</td>
                  <td align="left" rowspan="1" colspan="1">4.4 (2.1)</td>
                  <td align="left" rowspan="1" colspan="1">1.2 (1.2)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Jaw Drop</td>
                  <td align="left" rowspan="1" colspan="1">AU26</td>
                  <td align="left" rowspan="1" colspan="1">4.6 (3.3)</td>
                  <td align="left" rowspan="1" colspan="1">4.3 (3.2)</td>
                  <td align="left" rowspan="1" colspan="1">4.4 (3.3)</td>
                  <td align="left" rowspan="1" colspan="1">1.9 (1.4)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Chin Raiser</td>
                  <td align="left" rowspan="1" colspan="1">AU17</td>
                  <td align="left" rowspan="1" colspan="1">19.6 (9.2)</td>
                  <td align="left" rowspan="1" colspan="1">47.1* (10.4)</td>
                  <td align="left" rowspan="1" colspan="1">57.4*** (7.7)</td>
                  <td align="left" rowspan="1" colspan="1">10.1 (4.2)</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="nt101">
              <label/>
              <p>Mean values of the controller bars on FaceTool software for the four conditions to make changes to the facial parts are indicated using FACS (facial action coding system) names, accompanied by AU (Action Unit) numbers. Standard errors of the mean are shown in parentheses. Asterisks indicate values significantly larger than zero. <sup>+</sup>: <italic>p</italic>&lt;0.10; *: <italic>p</italic>&lt;0.05; **: <italic>p</italic>&lt;0.01; ***: <italic>p</italic>&lt;0.001.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>To further illustrate the correspondence between these results, <xref ref-type="fig" rid="pone-0050280-g002"><bold>Figure 2</bold></xref> depicts the emotions (happy or sad) expressed by each facial part of the upward tilted and downward tilted Noh masks. For the upward tilted Noh mask images, the eyebrows and the mouth turned out to have common features with those when creating sad expressions, whereas the eyes with those when making happy expressions (<xref ref-type="fig" rid="pone-0050280-g002"><bold>Figure 2</bold></xref><bold> (A)</bold>). This contingency overall tended to be reversed for the downward tilted Noh mask images (<xref ref-type="fig" rid="pone-0050280-g002"><bold>Figure 2</bold></xref><bold> (B)</bold>).</p>
        <fig id="pone-0050280-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>A schematic illustration summarizing the main results of Experiment 1.</title>
            <p>Depicted are the emotions represented differentially by each facial part of the upward tilted and downward tilted Noh masks.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.g002" position="float" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Experiment 2</title>
        <p>For each synthesized image (<xref ref-type="fig" rid="pone-0050280-g003"><bold>Figures 3</bold></xref><bold> and </bold><xref ref-type="fig" rid="pone-0050280-g004"><bold>4</bold></xref>), the proportion of the “happy” evaluation was determined based on the number of times with the “happy” evaluation out of the four repeated trials. Because the data points were given in the proportions, the data were transformed for the statistical analyses, using the equation <italic>r’</italic> = arcsin (√<italic>r</italic>), to make distributions more normal. Whereas the binomial choices are at the nominal level of measurement, this transformation allows treatment of the data at the interval scale <xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref>, <xref ref-type="bibr" rid="pone.0050280-Johnson1">[16]</xref>. For these choice proportions, a one-way repeated measures analysis of variance (ANOVA) with facial pattern (8 patterns) as a within-subject factor was conducted. <xref ref-type="fig" rid="pone-0050280-g005"><bold>Figure 5</bold></xref> shows the mean proportions of “happy” evaluations for each pattern. The main effect of the facial pattern turned out to be statistically significant (<italic>F</italic> [7,434] = 445.5, <italic>p</italic>&lt;0.001). Multiple comparisons with Bonferroni correction revealed that there were statistically significant differences between all the 16 combinations of patterns 1, 2, 3, 8 and patterns 4, 5, 6, 7 (all <italic>ps</italic>&lt;0.001). By contrast, no statistically significant differences were found between any combinations of patterns within patterns 1, 2, 3, 8 (all <italic>ps</italic>&gt;0. 308), nor within patterns 4, 5, 6, 7 (all <italic>ps</italic>&gt;0.143). Also, one-sample <italic>t</italic>-tests with Bonferroni correction compared the proportion of “happy” evaluations for each facial pattern with the chance level (i.e., 50%). For patterns 4, 5, 6, and 7, the proportions were significantly higher than the chance level (mean = 95.4%; <italic>t</italic> = 18.068–25.735, all <italic>ps</italic>&lt;0.001, corrected), whereas for patterns 1, 2, 3, and 8, the proportions were significantly lower than the chance level (mean = 12.1%; <italic>t</italic> = −19.458 – −8.926, all <italic>ps</italic>&lt;0.001, corrected). Seeing these data in light of the emotions expressed by each facial part shown in <xref ref-type="table" rid="pone-0050280-t002"><bold>Table 2</bold></xref> (and <xref ref-type="fig" rid="pone-0050280-g003"><bold>Figure 3</bold></xref>), the choice proportions best correspond to the emotions expressed by the mouth, rather than to the other facial parts or combinations of multiple facial parts. These results thus show that, irrespective of which eyebrows or eyes used, the synthesized images having the mouth of the upward tilted Noh mask image strongly tended to be evaluated as sad, whereas those having the mouth of the downward tilted Noh mask image strongly tended to be evaluated as happy.</p>
        <fig id="pone-0050280-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>The eight synthesized facial patterns of the Noh mask used in Experiment 2.</title>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.g003" position="float" xlink:type="simple"/>
        </fig>
        <fig id="pone-0050280-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Diagram depicting examples of trials in the test session of Experiment 2.</title>
            <p>The letters on the first and third displays indicate “Trial 1” and “Trial 2”, respectively.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.g004" position="float" xlink:type="simple"/>
        </fig>
        <fig id="pone-0050280-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Proportion of the “happy” evaluation for each synthesized facial pattern in Experiment 2.</title>
            <p>The dashed horizontal line indicates the chance proportion of the “happy” responses (i.e., 50%). Error bars indicate standard errors of the mean. Asterisks indicate statistically significant differences from the chance level (***: <italic>p</italic>&lt;0.001).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.g005" position="float" xlink:type="simple"/>
        </fig>
        <table-wrap id="pone-0050280-t002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.t002</object-id>
          <label>Table 2</label>
          <caption>
            <title>Description of the eight facial patterns of the synthesized Noh mask images used in Experiment 2.</title>
          </caption>
          <alternatives>
            <graphic id="pone-0050280-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.t002" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">facial part</td>
                  <td colspan="8" align="left" rowspan="1">facial pattern</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">1</td>
                  <td align="left" rowspan="1" colspan="1">2</td>
                  <td align="left" rowspan="1" colspan="1">3</td>
                  <td align="left" rowspan="1" colspan="1">4</td>
                  <td align="left" rowspan="1" colspan="1">5</td>
                  <td align="left" rowspan="1" colspan="1">6</td>
                  <td align="left" rowspan="1" colspan="1">7</td>
                  <td align="left" rowspan="1" colspan="1">8</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">head inclination</td>
                  <td align="left" rowspan="1" colspan="1">eyebrows</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">eyes</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">mouth</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">downward</td>
                  <td align="left" rowspan="1" colspan="1">upward</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">emotion expressed</td>
                  <td align="left" rowspan="1" colspan="1">eyebrows</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">eyes</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">mouth</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">happy</td>
                  <td align="left" rowspan="1" colspan="1">sad</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="nt102">
              <label/>
              <p>The upper half of the table describes head inclination of the images from which each facial part was cropped (upward tilted or downward tilted). For example, pattern 1 shows that the eyebrows, the eyes, and the mouth had all been synthesized using those of the upward tilted Noh mask image. The lower half of the table describes the emotions that are deemed to be expressed by each facial part of the upward and downward tilted Noh mask images (happy or sad), based on the results of Experiment 1.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>In addition, <xref ref-type="fig" rid="pone-0050280-g006"><bold>Figure 6</bold></xref> depicts numbers of participants for each proportion of the “happy” evaluations (i.e., 0%, 25%, 50%, 75%, and 100%). As apparent from the graph, for patterns 1, 2, 3, and 8, the largest numbers of participants evaluated the expressions as “sad” for all the four repeated trials (1/5 binomial tests; all <italic>ps</italic>&lt;0.001). In contrast, for patterns 4, 5, 6, and 7, the largest numbers of participants evaluated the expressions as “happy” for all the four repetitions (1/5 binomial tests; all <italic>ps</italic>&lt;0.001). Seeing these data again in light of <xref ref-type="table" rid="pone-0050280-t002"><bold>Table 2</bold></xref> and <xref ref-type="fig" rid="pone-0050280-g003"><bold>Figure 3</bold></xref>, the results further show that the participants’ evaluation of the emotional expressions was distinctively made based on the shape of the mouth.</p>
        <fig id="pone-0050280-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0050280.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Numbers of participants for each proportion of “happy” evaluation in Experiment 2, shown for each synthesized facial pattern.</title>
            <p>“100%” in this graph means that the facial pattern was evaluated as “happy” for all the four repeated presentations, whereas “0%” means that the pattern was evaluated as “sad” for all the four repetitions.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pone.0050280.g006" position="float" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>The present research examined the roles of different facial components in characterizing the emotional expressions of the Japanese Noh masks, in both contexts of active creation of facial expressions and passive emotion recognition of the synthesized facial patterns. In Experiment 1, we presented upward tilted and downward tilted Noh masks, which each corresponded to the stylistic gesture signifying happiness (<italic>terasu</italic>) and sadness (<italic>kumorasu</italic>). In these Noh mask images, the eyebrows, the eyes, and the mouth each expressed different emotion, forming composite expressions involving both happiness and sadness simultaneously. In Experiment 2, when presented with the Noh mask images of which the eyebrows, the eyes, and the mouth each expressed different emotion, participants primarily used the shape of the mouth in differentiating the emotions. It could thus be proposed that the mouth serves as a diagnostic feature in the categorical judgment of emotions when viewing the Noh masks. Taken together, these results suggest that Noh masks express chimeric emotional patterns that changes according to the actor’s head orientations, and that among different facial parts the mouth serves as the most distinctive feature in determining the overall emotional categories.</p>
      <p>The major question posed in the Introduction was how biologically-driven and cultural/conventional factors may play dominant roles when recognizing emotions of Noh masks. With regard to this question, the results of Experiment 2 seem most convincing. They clearly demonstrated that the judgment of emotional expressions of a Noh mask is predominantly made based on the shapes of the mouth, with the mouth of an upward/downward tilted Noh mask expressing sadness/happiness, respectively. Thus, when presented with the face of a Noh mask alone, the categorization of the emotional expressions seems to rely primarily on a biological feature such as the shape of the mouth, rather than on the traditionally formulated styles of the Noh drama. This further seems in agreement with the notion that the recognition of facial expressions is universal and thus is biologically-based <xref ref-type="bibr" rid="pone.0050280-Ekman2">[11]</xref>–<xref ref-type="bibr" rid="pone.0050280-Elfenbein2">[15]</xref>, even when the artificial masks are used instead of the human faces.</p>
      <p>Such importance of the mouth could be considered in light of the literature on facial recognition. Traditionally, Dunlap <xref ref-type="bibr" rid="pone.0050280-Dunlap1">[17]</xref> reported evidence of the superiority of the mouth in the recognition of emotions (see also <xref ref-type="bibr" rid="pone.0050280-Ruckmick1">[18]</xref>). More recent reports further focus on the cultural differences in the importance of different facial parts in recognizing emotions. Yuki et al. <xref ref-type="bibr" rid="pone.0050280-Yuki1">[19]</xref> presented emoticons to both Americans and Japanese, and found that Americans located expressions at the mouth, recognizing :) as happy and :(as sad, while Japanese found them in the eyes, seeing <sup>Λ</sup>_<sup>Λ</sup> as joyful and ;_; as tearful. Jack et al. <xref ref-type="bibr" rid="pone.0050280-Jack1">[20]</xref> analyzed eye movements of both Western and Eastern observers when recognizing emotional facial expressions, and found that Western observers distributed their fixations evenly across the face including the mouth, whereas Eastern observers persistently fixated the eye region while rarely gazing at the mouth. In a consistent way, Ozono et al. <xref ref-type="bibr" rid="pone.0050280-Ozono1">[21]</xref> showed that Americans focused on the lower half of a face when determining its trustworthiness, whereas Japanese emphasized the upper half. Despite these suggested cultural differences, our data involving Japanese participants and Japanese traditional art strongly supported the importance of the mouth <xref ref-type="bibr" rid="pone.0050280-Dunlap1">[17]</xref>–<xref ref-type="bibr" rid="pone.0050280-Ruckmick1">[18]</xref>. This may further favor the strong influence of biological factors in emotion recognition of Noh masks. Future studies involving participants from different cultures and different types of masks may confirm these possibilities.</p>
      <p>The overall trends of the present findings also seem consistent with those from the preceding studies using tilted Noh masks <xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref>–<xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref>. That is, these studies revealed that Noh masks tilted upwards tend to be recognized as sad, whereas those tilted downwards tend to be recognized as happy, as opposed to the traditional styles of the Noh drama. It seems worthwhile considering the potential factors that consistently cause these opposite trends. Regarding the present study, participants did not know the Noh rules <italic>terasu</italic>/<italic>kumorasu</italic>, suggesting that the observed trends may not directly reflect their cultural knowledge. The Noh drama has many stylistic rules other than those regarding the Noh masks, including inclination and successive movements of the actor’s body as well as the background chorus and instrumental music <xref ref-type="bibr" rid="pone.0050280-Inoue1">[3]</xref>. Observers take in all these information to appreciate the intended emotions. Consequently, during the actual performance of the Noh drama, these multiple conventional rules may holistically play a major role in the appreciation of emotions. For example, Nishimura et al. <xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref> proposed that the initial movements of the stylized actions, rather than the later ones, may determine the category of the emotions for that whole action. This was suggested to explain why the intended emotions are appreciated appropriately in the Noh drama, even if the stylistic rules sometimes appear to contradict with the biological mechanisms of emotion recognition. Thus, a plausible scenario could be that the dominance of biological factors observed when presented with the Noh masks alone is taken over by the cultural/conventional factors when the drama as a whole is involved. To elucidate the effects of such conventional factors, it would be beneficial to systematically manipulate information conveyed in the drama, such as the movements of multiple actors and/or background music.</p>
      <p>The notion that Noh masks express chimeric and composite emotional patterns, as suggested in Experiment 1, further leads to the assumption that the masks with any given head inclinations possess different composite expressions, each of which involves multiple emotions at a time. Such mysterious qualities seem to go in line with what is observed in the Western art. For example, Mona Lisa is suggested to change its expressions depending on which facial parts the observer looks at, thereby possessing an elusive quality in it <xref ref-type="bibr" rid="pone.0050280-Livingstone1">[22]</xref>. Bohrn et al. <xref ref-type="bibr" rid="pone.0050280-Bohrn1">[23]</xref> simulated this phenomenon using non-Mona-Lisa facial stimuli, by presenting a smiling mouth when the viewer looked at the eyes, and a neutral mouth when the viewer gazed at the mouth. The faces in this Mona-Lisa condition were evaluated as more attractive and trustworthy than the neutral faces, even though the viewers’ confidence on their own ratings were the lowest in the Mona-Lisa condition. Similar mysterious facial expressions are observed not only in Renaissance paintings but also more widely in Western art <xref ref-type="bibr" rid="pone.0050280-Gombrich1">[24]</xref>. With regard to the Japanese tradition of the Noh drama, “<italic>yugen</italic>”, or subtle profundity, is deemed to be the highest aesthetic principle <xref ref-type="bibr" rid="pone.0050280-Zeami1">[25]</xref>. Consequently, subtle and composite emotional expressions are more highly appreciated than the expression of a single pure emotion in the Noh drama. The present findings thus seem consistent with the potential of a Noh mask to convey countless different emotions (e.g., “<italic>mugen hyojo</italic>” as termed in the Introduction), despite its fixed physical properties.</p>
      <p>To summarize, the present study primarily suggested the dominance of biological factors such as the shape of the mouth when evaluating the emotions of Noh masks. They further proposed the potential influence by the conventional performing styles if the Noh drama as a whole is involved, as well as implications for an even higher aesthetic state such as <italic>yugen</italic>. In relation to these issues, the expertise of the participants to the Noh drama would be one important challenge for the future quest. That is, the present participants were naïve in terms of the performing skills of Noh, despite their basic knowledge about Noh. This may have led to the dominance of the biological factors in emotion recognition. In the course of the professional expertise, the trainees should learn the determined associations between certain head/body postures and corresponding emotional expressions. Thus, it might be plausible that highly skilled Noh actors tend to evaluate upward tilted Noh masks as happy (<italic>terasu</italic>) and downward tilted masks as sad (<italic>kumorasu</italic>), in accordance with the rules of Noh. These experts, compared with novices, may also have a more detailed and elaborate cognitive sketch on how different facial parts convey subtle emotional qualities. Also, it would be promising to include participants truly naïve to the Noh drama, such as those from North America or Europe, to examine the potential effect of cultural background including basic knowledge about Noh. Methodologically, the two-alternative forced choice procedure used in Experiment 2 seems effective so long as the study focuses on the categorical judgment of emotions. The promising alternatives, however, could be to use continuous scales or choice procedures with more options, which should provide stronger statistical power. It would also be beneficial to include a control condition using humans’ facial images, to examine similarities and differences between Noh masks and human faces. Actually, Lyons et al. <xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref> found that the decline of “happy” responses at large downward tilting angles for Japanese viewers was present only for Noh masks, not for human faces. Further investigations from these various perspectives should help to further elucidate how biologically-driven factors as well as conventional styles may influence the recognition of emotional information to attain higher aesthetic qualities in traditional performing art.</p>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Experiment 1</title>
        <p>The specific purpose of the first experiment was to examine to what extent facial expressions of an upward or downward tilted Noh mask shared common features with faces that are typically recognized as happy or sad. Participants actively changed facial expressions of a Noh mask image presented on a computer screen by moving each facial part, and either created happy or sad expressions, or imitated an upward or downward tilted Noh mask. Based on previous findings <xref ref-type="bibr" rid="pone.0050280-Nishimura1">[4]</xref>–<xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref>, we hypothesized that happy faces would have many common features with those imitating downward tilted faces, whereas sad faces with those imitating upward tilted faces.</p>
        <sec id="s4a1">
          <title>Participants</title>
          <p>Fourteen healthy Japanese adults (7 females and 7 males; age, 20–23 years; mean age = 21.4 years, <italic>SD</italic> = 1.0) participated. All participants in both experiments were university undergraduate students recruited at Nagoya, Japan, who were exposed to Western culture in comparable ways as Japanese people in general are. All participants in both experiments were familiar with Noh masks, either as images or objects, but had not received specialized training with Noh prior to participation. A preliminary enquiry had revealed that the same population of participants was ignorant of the Noh gestures <italic>terasu</italic>/<italic>kumorasu</italic> to signify happiness/sadness. All participants had normal or corrected-to-normal vision. The study was approved by the Ethics Committee of the Japan Science and Technology Agency. All participants from both experiments gave written informed consent upon agreement cooperate. They were not compensated for participation.</p>
        </sec>
        <sec id="s4a2">
          <title>Stimuli</title>
          <p>A frontal image of a Koomote mask was used for the beginning phase of the experiment (<xref ref-type="fig" rid="pone-0050280-g001"><bold>Figure 1</bold></xref>). The mask had been carved by Akira Kurabayashi, a Japanese professional Noh mask artist. Koomote is a mask that represents a cute young girl below 20 years of age <xref ref-type="bibr" rid="pone.0050280-Miura1">[26]</xref>. The size of the image presented was 11.4 degrees wide and 18.5 degrees long in terms of in visual angle. For the upward tilted and downward tilted conditions (see the Procedure section for details), also used were the images of the same Koomote mask that had been photographed at the vertical viewing angles of 10 degrees above (upward tilted) or below (downward tilted) front. These tilted images intended to show the examples of the expression of joy (<italic>terasu</italic>) and sorrow (<italic>kumorasu</italic>) in the conventional rules of Noh. All these images were copy-free and were downloaded from the artist’s website <xref ref-type="bibr" rid="pone.0050280-Noh1">[27]</xref>.</p>
        </sec>
        <sec id="s4a3">
          <title>Procedure</title>
          <p>FaceTool, a software for creating facial expressions, was used. The software had been developed by the laboratory of Professor Hiroshi Harashima, The University of Tokyo, Tokyo, Japan <xref ref-type="bibr" rid="pone.0050280-Morishima1">[28]</xref>. Using FaceTool, one can actively change the shapes of different facial parts, including the eyebrows, the eyes, the cheeks, the month, and so on, to create various facial expressions. The software had 23 horizontal bars as controllers, each of which labeled “eyebrow: inner brow raise”, “lip: lower lip depress”, and so on, which were used to manipulate shapes of each facial part. These actions of facial parts corresponded to the Action Unit (AU) used in FACS <xref ref-type="bibr" rid="pone.0050280-Ekman1">[6]</xref>, a system that enables description of humans’ facial expressions based on the movements of mimetic muscles.</p>
          <p>The experiment took place in a room dim, sound-attenuated room equipped with a personal computer. FaceTool software and the test stimuli were presented on a 48 cm (19.0 inches) flat-panel, LCD monitor (FlexScan S1932, EIZO, Ishikawa, Japan), whose dot response was deemed very fast. The display was located on a table in front of the participant, who sat on a comfortable chair. The distance between the monitor and the participant’s eyes was set at 57 cm, so that one centimeter on the screen corresponded to a visual angle of approximately one degree. By manipulating the controllers on FaceTool, participants changed the frontal image of the Noh mask to four different facial expressions: happy, sad, upward tilted, and downward tilted (<xref ref-type="fig" rid="pone-0050280-g001"><bold>Figure 1</bold></xref>). Because all the participants were Japanese, the Japanese terms <italic>“yorokobi”</italic>, <italic>“kanashimi”</italic>, <italic>“ue-muki”</italic>, and <italic>“shita-muki”</italic> were used to refer to these conditions, respectively. Within-subject design was used, so that all participants were exposed to these four conditions. Each condition was presented once, and the order was counterbalanced across participants. For the happy and sad conditions, participants were instructed to change the image so that they would feel that the face typically represents these emotions, while referring to no other facial images. For the upward tilted and downward tilted conditions, participants were told to change the frontal image of the mask by imitating an upward or downward tilted Koomote image that was simultaneously presented to the left of the frontal image. Changes to the facial components were made by scrolling the indicator at each controller from left to right, based on the extent to which each action was true for the intended facial expression. The rating value for each controller was given on a scale of 0 to 100. For all the participants and conditions, rating values at all the controllers were recorded. There was no limited time before participants completed each condition, which was terminated when participants signaled that they had finished creating the expression as instructed. The duration for the whole experiment accounted for approximately 30 minutes.</p>
        </sec>
      </sec>
      <sec id="s4b">
        <title>Experiment 2</title>
        <p>The results of Experiment 1 suggested that the upward and downward tilted Noh masks are a so-called chimera, in that different facial parts express different emotions. Based on these findings, the next question concerned how viewers may weight emotions expressed by different facial parts, when presented with a face each part of which expressing different emotions. If viewers use any certain facial part predominantly to judge the emotions of the whole face, then their evaluations would show distinctive patterns according to the shape of that facial part. Otherwise, if certain combinations of multiple facial parts play a more crucial role, then evaluations would exhibit more complex patterns. Experiment 2 introduced the context of passive facial recognition on a computer screen. Participants evaluated the emotions of the synthesized Noh mask images, of which the eyebrows, the eyes, and the mouth expressed different emotions, respectively.</p>
        <sec id="s4b1">
          <title>Participants</title>
          <p>Sixty-three healthy Japanese adults (29 females and 34 males; age, 18–22 years; mean age = 19.1 years, <italic>SD</italic> = 0.7), other than those included in Experiment 1, participated.</p>
        </sec>
        <sec id="s4b2">
          <title>Stimuli</title>
          <p>Frontal, upward tilted, and downward tilted images of the Koomtoe mask carved by Akira Kurabayashi, the identical ones as those used in Experiment 1 (<xref ref-type="fig" rid="pone-0050280-g001"><bold>Figures 1</bold></xref><bold> (A)</bold>, <bold>(D)</bold>, and <bold>(E)</bold>, respectively), were modified with Adobe Photoshop CS4, to create stimuli for Experiment 2. The facial areas involving the eyebrows, the eyes, and the mouth were each cropped from the upward tilted and downward tilted Noh mask images. These different areas were then overlaid to the frontal Noh mask image, so that the eyebrows, the eye and the mouth would each express different emotions. Because there were eight combinations of the facial parts, there were eight different synthesized facial patterns (<xref ref-type="fig" rid="pone-0050280-g003"><bold>Figure 3</bold></xref>; see <xref ref-type="table" rid="pone-0050280-t002"><bold>Table 2</bold></xref> for description of these patterns). The size of all these stimuli were 13.7 degrees wide and 22.6 degrees long in in terms of visual angle.</p>
        </sec>
        <sec id="s4b3">
          <title>Procedure</title>
          <p>The experiment took place in a room with a personal computer equipped for each participant. All participants were instructed and tested at a time. The test stimuli were presented on a 43 cm (17.0 inches) TFT LCD monitor (VL-17SE, Fujitsu, Kawasaki, Japan) located on a table in front of the participant, who sat on a comfortable chair. The distance between the monitor and the participant’s eyes was set at approximately 50 cm. The test stimuli were presented using Microsoft PowerPoint 2007. Before the main test session, there were three practice trials using images other than those for the test, for instruction of the general procedure. During the test session that followed, each of the eight different patterns of the synthesized Noh mask images was presented four times, thereby 32 trials forming the session. The order of these patterns presented was pseudo-randomized for each participant. <xref ref-type="fig" rid="pone-0050280-g004"><bold>Figure 4</bold></xref> shows the flow of the typical trials for the test session. For each trial, the number of that trial first appeared for four seconds, followed by the synthesized Noh mask image for eight seconds at the center of the display on a white background. The duration of the presentation of stimuli was controlled by a personal computer, and the displays switched automatically following the determined durations, regardless of the participants’ responses. Participants were informed during the instruction that they would not be allowed to terminate the session on the halfway. Participants answered whether each displayed Noh mask image expressed happy or sad emotions (using the Japanese terms “<italic>yorokobi</italic>” or “<italic>kanashimi</italic>”), by filling in the evaluation sheet placed on a table in front of them. Following Lyons et al. <xref ref-type="bibr" rid="pone.0050280-Lyons1">[5]</xref>, the answer had to be given in the form of a two-alternative forced choice, and thus no answers in between were allowed. Use of a comparable procedure enables effective comparisons between the preceding and the present studies. More recent studies on emotional facial expressions also employed this procedure <xref ref-type="bibr" rid="pone.0050280-Calvo1">[29]</xref>, <xref ref-type="bibr" rid="pone.0050280-Nomi1">[30]</xref>. The duration of the test session was approximately seven minutes, and the whole experiment lasted for approximately 20 minutes.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="pone.0050280-Komparu1">
        <label>1</label>
        <mixed-citation publication-type="other" xlink:type="simple">Komparu K (1983) The Noh theatre: principles and perspectives. New York, USA and Tokyo, Japan: Weatherhill/Tankosha.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Waley1">
        <label>2</label>
        <mixed-citation publication-type="other" xlink:type="simple">Waley A (2009) The Noh plays of Japan. Tokyo, Japan: Tuttle Publishing.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Inoue1">
        <label>3</label>
        <mixed-citation publication-type="other" xlink:type="simple">Inoue Y (2003) Noh-ni-akusesu (Access to Noh). Kyoto, Japan: Tankosha (in Japanese).</mixed-citation>
      </ref>
      <ref id="pone.0050280-Nishimura1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nishimura</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kawai</surname><given-names>N</given-names></name> (<year>2010</year>) <article-title>Do Noh masks communicate emotions conveyed by the Noh drama?</article-title> <source>Cogn Stud</source> <volume>17</volume>: <fpage>750</fpage>–<lpage>760</lpage> (in Japanese)..</mixed-citation>
      </ref>
      <ref id="pone.0050280-Lyons1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lyons</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Campbell</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Plante</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Coleman</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kamachi</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>The Noh mask effect: vertical viewpoint dependence on facial expression perception</article-title>. <source>Proc R Soc Lond B Biol Sci</source> <volume>267</volume>: <fpage>2239</fpage>–<lpage>2245</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Ekman1">
        <label>6</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ekman P, Friesen WV (1978) Facial action coding system. Palo Alto, CA: Consulting Psychologists Press.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Kappas1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kappas</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hess</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Barr</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Klerk</surname><given-names>R</given-names></name> (<year>1994</year>) <article-title>Angle of regard: the effect of vertical viewing angle on the perception of facial expressions</article-title>. <source>J Nonverbal Behav</source> <volume>18</volume>: <fpage>263</fpage>–<lpage>280</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Minoshita1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Minoshita</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sato</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Morita</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Tagawa</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kikuchi</surname><given-names>T</given-names></name> (<year>1999</year>) <article-title>The Noh mask test for analysis of recognition of facial expression</article-title>. <source>Psychiatry Clin Neurosci</source> <volume>53</volume>: <fpage>83</fpage>–<lpage>89</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Minoshita2">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Minoshita</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sato</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Morita</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Nakamura</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Matsuzaki</surname><given-names>I</given-names></name>, <etal>et al</etal>. (<year>1997</year>) <article-title>Assessing recognition of affects in facial expression through the use of Nomen</article-title>. <source>Jpn J Ergonom</source> <volume>33</volume>: <fpage>79</fpage>–<lpage>86</lpage> (in Japanese)..</mixed-citation>
      </ref>
      <ref id="pone.0050280-Minoshita3">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Minoshita</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Morita</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Yamashita</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Yoshikawa</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kikuchi</surname><given-names>T</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Recognition of affect in facial expression using the Noh Mask Test: Comparison of individuals with schizophrenia and normal controls</article-title>. <source>Psychiat Clin Neurosci</source> <volume>59</volume>: <fpage>4</fpage>–<lpage>10</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Ekman2">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Friesen</surname><given-names>WV</given-names></name> (<year>1971</year>) <article-title>Constants across cultures in the face and emotion</article-title>. <source>J Pers Soc Psychol</source> <volume>17</volume>: <fpage>124</fpage>–<lpage>129</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Ekman3">
        <label>12</label>
        <mixed-citation publication-type="other" xlink:type="simple">Ekman P (1989) The argument and evidence about universals in facial expressions of emotion. In: Wagner H, Manstead A (eds) Handbook of social psychophysiology. New York, USA: Wiley.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Ekman4">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name> (<year>1992</year>) <article-title>Facial expressions of emotions: New findings, new questions</article-title>. <source>Psychol Sci</source> <volume>3</volume>: <fpage>34</fpage>–<lpage>38</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Elfenbein1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elfenbein</surname><given-names>HA</given-names></name>, <name name-style="western"><surname>Ambady</surname><given-names>N</given-names></name> (<year>2002</year>) <article-title>On the universality and cultural specificity of emotion recognition: A meta-analysis</article-title>. <source>Psychol Bull</source> <volume>128</volume>: <fpage>203</fpage>–<lpage>235</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Elfenbein2">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elfenbein</surname><given-names>HA</given-names></name>, <name name-style="western"><surname>Ambady</surname><given-names>N</given-names></name> (<year>2003</year>) <article-title>When familiarity breeds accuracy: Cultural exposure and facial emotion recognition</article-title>. <source>J Pers Soc Psychol</source> <volume>85</volume>: <fpage>276</fpage>–<lpage>290</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Johnson1">
        <label>16</label>
        <mixed-citation publication-type="other" xlink:type="simple">Johnson NL, Kotz S, Kemp AW (1992) Univariate discrete distributions, 2nd edition. New York, USA: Wiley.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Dunlap1">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dunlap</surname><given-names>K</given-names></name> (<year>1927</year>) <article-title>The role of the eye muscles and mouth muscles in the expression of emotions</article-title>. <source>Genet Psychol Monogr</source> <volume>2</volume>: <fpage>199</fpage>–<lpage>233</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Ruckmick1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruckmick</surname><given-names>CA</given-names></name> (<year>1921</year>) <article-title>A preliminary study of emotions</article-title>. <source>Psychol Monogr</source> <volume>30</volume>: <fpage>30</fpage>–<lpage>35</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Yuki1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yuki</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Maddux</surname><given-names>WW</given-names></name>, <name name-style="western"><surname>Masuda</surname><given-names>T</given-names></name> (<year>2007</year>) <article-title>Are the windows to the soul the same in the East and West? Cultural differences in using the eyes and mouth as cues to recognize emotions in Japan and the United States</article-title>. <source>J Exp Soc Psychol</source> <volume>43</volume>: <fpage>303</fpage>–<lpage>311</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Jack1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jack</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Blais</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Scheepers</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Schyns</surname><given-names>PG</given-names></name>, <name name-style="western"><surname>Caldara</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>Cultural confusions show that facial expressions are not universal</article-title>. <source>Curr Biol</source> <volume>19</volume>: <fpage>1543</fpage>–<lpage>1548</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Ozono1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ozono</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Watabe</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Yoshikawa</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Nakashima</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Rule</surname><given-names>NO</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>What’s in a smile? Cultural differences in the effects of smiling on judgments of trustworthiness</article-title>. <source>Lett Evol Behav Sci</source> <volume>1</volume>: <fpage>15</fpage>–<lpage>18</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Livingstone1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Livingstone</surname><given-names>MS</given-names></name> (<year>2000</year>) <article-title>Is it warm? Is it real? Or just low spatial frequency?</article-title> <source>Science</source> <volume>290</volume>: <fpage>1299</fpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Bohrn1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bohrn</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Carbon</surname><given-names>C-C</given-names></name>, <name name-style="western"><surname>Hutzler</surname><given-names>F</given-names></name> (<year>2010</year>) <article-title>Mona Lisa’s smile – perception or deception?</article-title> <source>Psychol Sci</source> <volume>21</volume>: <fpage>378</fpage>–<lpage>380</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Gombrich1">
        <label>24</label>
        <mixed-citation publication-type="other" xlink:type="simple">Gombrich EH (1999) The Story of Art. London, UK: Phaidon.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Zeami1">
        <label>25</label>
        <mixed-citation publication-type="other" xlink:type="simple">Zeami M (2006) The Flowering Spirit (Fushikaden). Tokyo, Japan: Kodansha International.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Miura1">
        <label>26</label>
        <mixed-citation publication-type="other" xlink:type="simple">Miura H (2004) Omote kara tadoru Nogaku hyaku-ichi-ban (Noh dramas introduced with the masks). Kyoto, Japan: Tankyosha (in Japanese).</mixed-citation>
      </ref>
      <ref id="pone.0050280-Noh1">
        <label>27</label>
        <mixed-citation publication-type="other" xlink:type="simple">Noh mask Artist Akira Kurabayashi’s website. Available: <ext-link ext-link-type="uri" xlink:href="http://www.nohmask.net/nohmasks/index.html" xlink:type="simple">http://www.nohmask.net/nohmasks/index.html</ext-link>. Accessed 07 September 2012.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Morishima1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morishima</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Yagi</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Kaneko</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Harashima</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yachida</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>1998</year>) <article-title>Construction of standard software for face recognition and synthesis</article-title>. <source>Tech Rep IEICE</source> <volume>PRMU97–282</volume>: <fpage>129</fpage>–<lpage>136</lpage> (in Japanese)..</mixed-citation>
      </ref>
      <ref id="pone.0050280-Calvo1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calvo</surname><given-names>MG</given-names></name>, <name name-style="western"><surname>Nummenmaa</surname><given-names>L</given-names></name> (<year>2011</year>) <article-title>Time course of discrimination between emotional facial expression: The role of visual display</article-title>. <source>Vision Res</source> <volume>51</volume>: <fpage>1751</fpage>–<lpage>1759</lpage>.</mixed-citation>
      </ref>
      <ref id="pone.0050280-Nomi1">
        <label>30</label>
        <mixed-citation publication-type="other" xlink:type="simple">Nomi JS, Rhodes MG, Cleary AM (in press) Emotional facial expressions differentially influence predictions and performance for face recognition. Cogn Emot.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>